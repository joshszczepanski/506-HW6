---
title: "506-HW6"
output: html_document
date: "2025-12-04"
---

```{r}
library(Rcpp)
library(e1071)
library(knitr)


# 1)

#' Compute the mean of a numeric vector
#'
#' @param x Numeric vector
#' @return Mean of x
#' @examples
#' C_mean(c(1,2,3))
cppFunction('
  double C_mean(NumericVector x) {
    int n = x.size();
    double sum = 0.0;
    for(int i = 0; i < n; i++){
      sum += x[i];
    }
    return sum / n;
  }
')

#' Compute the k-th central moment of a numeric vector
#'
#' @param x Numeric vector
#' @param k Integer order of the moment
#' @return k-th central moment of x
#' @examples
#' C_moment(c(1,2,3), 2)
cppFunction('
  double C_moment(NumericVector x, int k) {
    int n = x.size();
    
    // Compute mean directly inside this function
    double mu = 0.0;
    for(int i = 0; i < n; i++){
      mu += x[i];
    }
    mu /= n;

    // Accumulate central moment
    double acc = 0.0;
    for(int i = 0; i < n; i++){
      double diff = x[i] - mu;
      acc += pow(diff, k);
    }

    return acc / n;   // divide by n to match e1071::moment()
  }
')

set.seed(2025)
x <- rnorm(1000)   # "moderate" length vector

# Compare 2nd, 3rd, 4th central moments
results <- vapply(2:4, function(k) {
  c(
    k = as.numeric(k),
    C_moment = C_moment(x, k),
    e1071_moment = moment(x, order = k, center = TRUE)
  )
}, numeric(3))

# Display results in a clean table
knitr::kable(t(results), digits = 6, col.names = c("Order", "C_moment", "e1071::moment"))

# Check agreement for third moment
all.equal(
  C_moment(x, 3),
  moment(x, order = 3, center = TRUE)
)
```

```{r}


# 2)
library(parallel)

# a)
# waldCI


#' Wald Confidence Interval Class
#'
#' @slot est Numeric estimate
#' @slot sterr Standard error
#' @slot level Confidence level
setClass(
  "waldCI",
  slots = list(
    est   = "numeric",
    sterr = "numeric",
    level = "numeric"
  )
)

#' Show method for waldCI
#'
#' @param object A waldCI object
#' @return Prints estimate, SE, level, and CI
setMethod("show", "waldCI", function(object) {
  alpha <- 1 - object@level
  z <- qnorm(1 - alpha/2)

  cat("Wald CI:\n")
  cat("  Estimate:", object@est, "\n")
  cat("  SE:", object@sterr, "\n")
  cat("  Level:", object@level, "\n")
  cat("  CI:", object@est - z*object@sterr, "to",
                 object@est + z*object@sterr, "\n\n")
})

# bootstrapWaldCI


#' Bootstrap Wald Confidence Interval Class
#'
#' Inherits from waldCI and adds bootstrap functionality
#'
#' @slot fun Function used to compute statistic
#' @slot data Dataset used for bootstrap
#' @slot reps Number of bootstrap repetitions
#' @slot compute Character string ("serial" or "parallel")
#' @slot boots Numeric vector of bootstrap draws
setClass(
  "bootstrapWaldCI",
  contains = "waldCI",
  slots = list(
    fun     = "function",
    data    = "ANY",
    reps    = "numeric",
    compute = "character",
    boots   = "numeric"
  )
)

# 3. Helper function

#' Perform one bootstrap resample
#'
#' @param fun Function to compute statistic
#' @param data Data frame to resample
#' @return Scalar statistic from resampled data
bootstrap_once <- function(fun, data) {
  idx <- sample(seq_len(nrow(data)), replace = TRUE)
  fun(data[idx, , drop = FALSE])
}

# Constructor

#' Construct a bootstrapWaldCI object
#'
#' @param fun Function returning scalar statistic
#' @param data Data frame
#' @param reps Number of bootstrap repetitions
#' @param level Confidence level
#' @param compute "serial" or "parallel"
#' @return A bootstrapWaldCI object
#' @examples
#' makeBootstrapCI(function(x) mean(x$Sepal.Length), iris, reps = 100)
makeBootstrapCI <- function(fun, data, reps = 100,
                            level = 0.95,
                            compute = c("serial", "parallel")) {

  compute <- match.arg(compute)

  # Run bootstrap
  if (compute == "serial") {
    boots <- replicate(reps, bootstrap_once(fun, data))
  } else {
    cores <- detectCores()
    cl <- makeCluster(cores)
    clusterExport(cl, c("fun", "data", "bootstrap_once"),
                  envir = environment())
    boots <- unlist(parLapply(cl, 1:reps, function(i) bootstrap_once(fun, data)))
    stopCluster(cl)
  }

  # Estimate + SE
  est   <- mean(boots)
  sterr <- sd(boots)

  # Return new object
  new("bootstrapWaldCI",
      est     = est,
      sterr   = sterr,
      level   = level,
      fun     = fun,
      data    = data,
      reps    = reps,
      compute = compute,
      boots   = boots)
}

# rebootstrap()

#' Re-run bootstrap on an existing bootstrapWaldCI object
#'
#' @param object A bootstrapWaldCI object
#' @return Updated bootstrapWaldCI object
setGeneric("rebootstrap", function(object) standardGeneric("rebootstrap"))

setMethod("rebootstrap", "bootstrapWaldCI", function(object) {
  if (object@compute == "serial") {
    boots <- replicate(object@reps, bootstrap_once(object@fun, object@data))
  } else {
    cores <- detectCores()
    cl <- makeCluster(cores)
    clusterExport(cl, c("object", "bootstrap_once"), envir = environment())
    boots <- unlist(parLapply(cl, 1:object@reps, function(i) bootstrap_once(object@fun, object@data)))
    stopCluster(cl)
  }

  # Update slots
  object@boots <- boots
  object@est   <- mean(boots)
  object@sterr <- sd(boots)
  object
})

# b)

library(ggplot2)

# Example: mean of diamonds$y
ci1 <- makeBootstrapCI(
  function(x) mean(x$y),
  data = ggplot2::diamonds,
  reps = 1000
)
ci1
rebootstrap(ci1)

# Example: coefficient on disp in mtcars
dispCoef <- function(data) {
  fit <- lm(mpg ~ cyl + disp + wt, data = data)
  coef(fit)[["disp"]]
}
ci2 <- makeBootstrapCI(dispCoef, mtcars, reps = 1000)
ci2
rebootstrap(ci2)

# Timing comparison
system.time(makeBootstrapCI(dispCoef, mtcars, reps = 2000, compute = "serial"))
system.time(makeBootstrapCI(dispCoef, mtcars, reps = 2000, compute = "parallel"))

```

```{r}

# 3)

# 1. Load packages
library(lme4)
library(dplyr)
library(ggplot2)
library(parallel)  # for part (b)



set.seed(123)
n <- 3e6

## 1. Demographics
age <- pmin(pmax(rnorm(n, mean = 30, sd = 8), 16), 70)

employment_status <- factor(
  sample(c("student","full_time","part_time","unemployed"),
         n, TRUE, prob = c(0.35,0.35,0.2,0.1))
)

country <- factor(
  sample(c("US","India","Lithuania","Germany","Nigeria","Other"),
         n, TRUE, prob = c(6, 5, .1, 3, .2, 10))
)

device_type <- factor(
  sample(c("desktop","laptop","tablet","phone"),
         n, TRUE, prob = c(0.25,0.4,0.1,0.25))
)

course_difficulty <- factor(
  sample(c("intro","intermediate","advanced"),
         n, TRUE, prob = c(0.5,0.3,0.2)),
  ordered = TRUE
)

## 2. Prior GPA
base_gpa <- 3.0 + 0.2 * (age - 30) / 10 +
  ifelse(employment_status == "student", 0.1, 0) -
  ifelse(employment_status == "unemployed", 0.05, 0)

prior_gpa <- pmin(pmax(rnorm(n, mean = base_gpa, sd = 0.4), 0), 4)

## 3. Weekly study hours
study_mean <- 5 + ifelse(device_type %in% c("desktop","laptop"), 1.5, 0) +
  ifelse(employment_status == "full_time", -1, 0) +
  ifelse(employment_status == "student", 1.2, 0) +
  ifelse(course_difficulty == "advanced", 1.5, 0) +
  ifelse(course_difficulty == "intro", -0.5, 0)

weekly_study_hours <- pmax(rnorm(n, mean = study_mean, sd = 2), 0)

## 4. Engagement
lambda_forum <- pmax(0.2 + 0.15 * weekly_study_hours + 0.5 * (prior_gpa - 3) +
                       ifelse(course_difficulty == "advanced", 1, 0),
                     0.05)

forum_posts <- rpois(n, lambda_forum)

lambda_quiz <- pmax(1 + 0.25 * weekly_study_hours + 0.8 * (prior_gpa - 2.5) +
                      ifelse(course_difficulty == "advanced", 0.5, 0) +
                      ifelse(course_difficulty == "intro", -0.3, 0),
                    0.1)

quiz_attempts <- rpois(n, lambda_quiz)

session_minutes <- pmax(weekly_study_hours * 60 *
                          ifelse(device_type %in% c("phone","tablet"), 0.8, 1.0) *
                          exp(rnorm(n, 0, 0.15)),
                        10)

## 5. Paid subscription
logit_paid <- -1.2 + 0.6 * (prior_gpa - 3) + 0.25 * (weekly_study_hours - 5) +
  ifelse(country %in% c("US","Germany"), 0.5, 0) -
  ifelse(country == "Nigeria", 0.4, 0)

p_paid <- plogis(logit_paid)
paid_subscription <- rbinom(n, 1, p_paid)

## 6. Final score
difficulty_penalty <- ifelse(course_difficulty=="intro", -5,
                             ifelse(course_difficulty=="advanced", 5, 0))

raw_score <- 60 + 10 * (prior_gpa - 3) + 1.5 * weekly_study_hours +
  0.4 * forum_posts + 0.2 * quiz_attempts + difficulty_penalty + rnorm(n, 0, 8)

final_score <- pmin(pmax(raw_score, 0), 100)

## 7. Completion
logit_complete <- -4 + 0.06 * final_score + 0.02 * forum_posts +
  0.01 * quiz_attempts + 0.6 * paid_subscription -
  0.2 * (course_difficulty == "advanced")

p_complete <- plogis(logit_complete)
completed_course <- rbinom(n, 1, p_complete)

## 8. Dropout
dropout_base <- 0.6 - 0.02 * weekly_study_hours - 0.01 * forum_posts -
  0.01 * quiz_attempts - 0.03 * (final_score - 60) / 10 +
  0.3 * (course_difficulty == "advanced")

dropout_base <- pmin(pmax(dropout_base, 0.05), 0.95)
early_dropout <- rbinom(n, 1, dropout_base)

time_to_dropout <- rep(NA_real_, n)
mask <- (early_dropout == 1 & completed_course == 0)
time_to_dropout[mask] <- pmax(rgamma(sum(mask), shape = 2, rate = 0.5), 0.5)
early_dropout[completed_course == 1] <- 0

## Final dataset
df <- data.frame(
  age,
  country,
  device_type,
  employment_status,
  course_difficulty,
  prior_gpa,
  weekly_study_hours,
  forum_posts,
  quiz_attempts,
  session_minutes,
  paid_subscription,
  final_score,
  completed_course,
  early_dropout,
  time_to_dropout,
  stringsAsFactors = FALSE
)

rm(age, country, device_type, employment_status, course_difficulty,
   prior_gpa, weekly_study_hours, forum_posts, quiz_attempts,
   session_minutes, paid_subscription, final_score, completed_course,
   early_dropout, time_to_dropout, base_gpa, difficulty_penalty,
   dropout_base, lambda_quiz, lambda_forum, logit_complete, logit_paid,
   mask, n, p_complete, p_paid, raw_score, study_mean)

cat("Data.frame `df` is", format(object.size(df), units = "MB"), "\n")

library(lme4)
library(dplyr)
library(ggplot2)

# Split data by country
df_split <- split(df, df$country)

# Function to standardize predictors within each country
standardize <- function(x) (x - mean(x)) / sd(x)

# Fit models and record runtime
model_results <- lapply(names(df_split), function(cntry) {
  dat <- df_split[[cntry]]
  
  dat <- dat %>%
    mutate(
      prior_gpa_z = standardize(prior_gpa),
      forum_posts_z = standardize(forum_posts),
      quiz_attempts_z = standardize(quiz_attempts)
    )
  
  t0 <- Sys.time()
  fit <- glmer(
    completed_course ~ prior_gpa_z + forum_posts_z + quiz_attempts_z + (1 | device_type),
    data = dat,
    family = binomial
  )
  t1 <- Sys.time()
  
  list(
    country = cntry,
    model = fit,
    runtime = as.numeric(difftime(t1, t0, units = "secs")),
    coef_forum = fixef(fit)["forum_posts_z"]
  )
})

# Extract and plot coefficients
coef_df <- do.call(rbind, lapply(model_results, function(x) {
  data.frame(country = x$country, coef = x$coef_forum, runtime = x$runtime)
}))

ggplot(coef_df, aes(x = reorder(country, coef), y = coef)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Estimated Coefficients for Forum Posts by Country",
       x = "Country", y = "Coefficient")

# Show runtimes
coef_df[, c("country", "runtime")]


library(parallel)

# Parallelized model fitting
countries <- unique(df$country)
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(lme4))
clusterExport(cl, varlist = c("df", "standardize"))

t_start <- Sys.time()

model_fast <- parLapply(cl, countries, function(cntry) {
  dat <- df[df$country == cntry, ]
  
  dat$prior_gpa_z <- standardize(dat$prior_gpa)
  dat$forum_posts_z <- standardize(dat$forum_posts)
  dat$quiz_attempts_z <- standardize(dat$quiz_attempts)
  
  fit <- glmer(
    completed_course ~ prior_gpa_z + forum_posts_z + quiz_attempts_z + (1 | device_type),
    data = dat,
    family = binomial
  )
  
  list(country = cntry, coef_forum = fixef(fit)["forum_posts_z"])
})

stopCluster(cl)
t_end <- Sys.time()

# Confirm results match
fast_df <- do.call(rbind, lapply(model_fast, as.data.frame))
all.equal(sort(fast_df$coef_forum), sort(coef_df$coef))  # Should be TRUE

# Report total runtime
total_runtime <- as.numeric(difftime(t_end, t_start, units = "secs"))
cat("Total runtime for parallel script:", round(total_runtime, 2), "seconds\n")

```


```{r}
# 4)

library(tidyverse)

# Load dataset

tennis <- read_csv(
  "https://raw.githubusercontent.com/JeffSackmann/tennis_atp/refs/heads/master/atp_matches_2019.csv"
)

n_tourneys <- tennis %>%
  distinct(tourney_id) %>%
  nrow()

n_tourneys


# (b)

winners <- tennis %>%
  filter(round == "F") %>%
  group_by(winner_name) %>%
  summarise(tourneys_won = n(), .groups = "drop") %>%
  arrange(desc(tourneys_won))

winners

# Players who won more than one tournament:
multi_winners <- winners %>%
  filter(tourneys_won > 1)

multi_winners

# Maximum number of tournaments won:
max_won <- max(winners$tourneys_won)
max_won

# Identify the players with that maximum:
top_winners <- winners %>%
  filter(tourneys_won == max_won)

top_winners


# (c) 

ace_diff <- tennis %>%
  mutate(diff = w_ace - l_ace) %>%
  pull(diff)

mean_observed <- mean(ace_diff, na.rm = TRUE)
mean_observed

set.seed(123)

perm_dist <- map_dbl(1:1000, ~{
  tennis %>%
    mutate(
      flip = sample(c(TRUE, FALSE), n(), replace = TRUE),
      aceA = if_else(flip, w_ace, l_ace),
      aceB = if_else(flip, l_ace, w_ace)
    ) %>%
    summarise(diff = mean(aceA - aceB, na.rm = TRUE)) %>%
    pull(diff)
})

# Two-sided p-value:
p_val <- mean(abs(perm_dist) >= abs(mean_observed))
p_val


win_rates <- tennis %>%
  select(winner_name, loser_name) %>%
  pivot_longer(
    cols = everything(),
    names_to = "result",
    values_to = "player"
  ) %>%
  mutate(win = if_else(result == "winner_name", 1, 0)) %>%
  group_by(player) %>%
  summarise(
    matches = n(),
    wins = sum(win),
    win_rate = wins / matches,
    .groups = "drop"
  ) %>%
  filter(matches >= 5) %>%     # restrict to players with â‰¥ 5 matches
  arrange(desc(win_rate))

win_rates

# Player(s) with the highest win rate:
best <- win_rates %>%
  filter(win_rate == max(win_rate))

best

```
